script: train.py
arguments: [--images, /data, --weights, ./outputs/, --batch-size, 16, --epochs, 25, --lr, 0.001, --workers, 4, --vis-images, 200, --vis-freq, 10, --logs, ./logs, --image-size, 256, --aug-scale, 0.05, --aug-angle, 15]
target: gpu-cluster
framework: Python
communicator: None
nodeCount: 1
environment:
  environmentVariables:
    EXAMPLE_ENV_VAR: EXAMPLE_VALUE
  python:
    userManagedDependencies: false
    interpreterPath: python
    condaDependenciesFile: aml_config/train-conda.yml
  docker:
    enabled: true
    baseImage: mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04
    sharedVolumes: true
    gpuSupport: true
mpi:
  processCountPerNode: 1
data:
  training_data:
    dataLocation:
      dataset:
        id: c7e23b60-04c8-46dc-96c5-d9f741f6234b
    mechanism: mount
    pathOnCompute: /data
    environmentVariableName: training_data
    createOutputDirectories: false
    overwrite: false
